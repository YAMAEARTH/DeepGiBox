use std::time::Duration;
use anyhow::Result;
use decklink_rust::{
    HeadlessProcessor, HeadlessConfig, CaptureConfig, ColorSpace,
    PostProcessingConfig, TrackingConfig, OverlayConfig, KeyingConfig, OutputConfig
};
use decklink_rust::headless::{PreprocessingConfig, InferenceConfig};

fn main() -> Result<()> {
    println!("DeepGI Standard I/O Pipeline - Headless Processing Test");
    println!("=======================================================");
    
    // List available devices
    let devices = decklink_rust::devicelist();
    if devices.is_empty() {
        println!("‚ùå No DeckLink devices found");
        return Ok(());
    }
    
    println!("Available devices:");
    for (i, name) in devices.iter().enumerate() {
        println!("  {}: {}", i, name);
    }
    println!();
    
    // Show available test configurations
    println!("Test Configurations:");
    println!("  1. Capture Only - Basic frame capture test");
    println!("  2. Preprocessing Pipeline - Capture + Preprocessing");
    println!("  3. AI Inference Pipeline - Preprocessing + Inference + Post-processing");
    println!("  4. Complete Pipeline - All stages with tracking and overlay");
    println!();
    
    // Configure test scenarios following DeepGI standards
    let test_configs = vec![
        // Test 1: Capture only
        HeadlessConfig {
            capture_config: CaptureConfig {
                device_index: 0,
                source_id: 100,
                expected_colorspace: ColorSpace::BT709,
            },
            preprocessing: None,
            inference: None,
            postprocessing: None,
            tracking: None,
            overlay: None,
            keying: None,
            output: None,
            max_runtime: Some(Duration::from_secs(5)),
            enable_detailed_logging: false,
            ..Default::default()
        },
        
        // Test 2: Preprocessing pipeline
        HeadlessConfig {
            capture_config: CaptureConfig {
                device_index: 0,
                source_id: 200,
                expected_colorspace: ColorSpace::BT709,
            },
            preprocessing: Some(PreprocessingConfig {
                target_width: 640,
                target_height: 480,
                normalize: true,
            }),
            inference: None,
            postprocessing: None,
            tracking: None,
            overlay: None,
            keying: None,
            output: None,
            max_runtime: Some(Duration::from_secs(8)),
            enable_detailed_logging: false,
            ..Default::default()
        },
        
        // Test 3: AI inference pipeline
        HeadlessConfig {
            capture_config: CaptureConfig {
                device_index: 0,
                source_id: 300,
                expected_colorspace: ColorSpace::BT709,
            },
            preprocessing: Some(PreprocessingConfig {
                target_width: 640,
                target_height: 480,
                normalize: true,
            }),
            inference: Some(InferenceConfig {
                model_name: "yolov8n".to_string(),
                confidence_threshold: 0.5,
            }),
            postprocessing: Some(PostProcessingConfig {
                nms_threshold: 0.45,
                max_detections: 50,
            }),
            tracking: None,
            overlay: None,
            keying: None,
            output: None,
            max_runtime: Some(Duration::from_secs(10)),
            enable_detailed_logging: false,
            stats_interval: Duration::from_secs(2),
            ..Default::default()
        },
        
        // Test 4: Complete DeepGI pipeline
        HeadlessConfig {
            capture_config: CaptureConfig {
                device_index: 0,
                source_id: 400,
                expected_colorspace: ColorSpace::BT709,
            },
            preprocessing: Some(PreprocessingConfig {
                target_width: 1920,
                target_height: 1080,
                normalize: true,
            }),
            inference: Some(InferenceConfig {
                model_name: "yolov8s".to_string(),
                confidence_threshold: 0.6,
            }),
            postprocessing: Some(PostProcessingConfig {
                nms_threshold: 0.45,
                max_detections: 100,
            }),
            tracking: Some(TrackingConfig { enabled: true }),
            overlay: Some(OverlayConfig {
                show_labels: true,
                show_confidence: true,
            }),
            keying: Some(KeyingConfig {
                enable_chroma_key: true,
            }),
            output: Some(OutputConfig {
                format: "h264".to_string(),
                enable_streaming: true,
            }),
            max_runtime: Some(Duration::from_secs(15)),
            enable_detailed_logging: true,
            stats_interval: Duration::from_secs(2),
            max_frames: None,
        },
    ];
    
    // Run each test configuration
    for (i, config) in test_configs.iter().enumerate() {
        println!("üß™ Running Test Configuration {} of {}", i + 1, test_configs.len());
        println!("{}", "‚îÄ".repeat(60));
        
        let mut processor = HeadlessProcessor::new(config.clone());
        
        if let Err(e) = processor.run() {
            eprintln!("‚ùå Test failed: {}", e);
        }
        
        if i < test_configs.len() - 1 {
            println!("‚è∏Ô∏è  Waiting 3 seconds before next test...");
            std::thread::sleep(Duration::from_secs(3));
            println!();
        }
    }
    
    println!("üéâ All DeepGI Standard I/O Pipeline tests completed!");
    println!();
    println!("üìã Test Summary:");
    println!("  ‚úÖ Verified standard packet flow: RawFramePacket -> TensorInputPacket -> RawDetectionsPacket");
    println!("  ‚úÖ Validated stage interfaces: DetectionsPacket -> OverlayPlanPacket -> KeyingPacket");
    println!("  ‚úÖ Confirmed pipeline metrics and error handling");
    println!("  ‚úÖ Tested modular stage configuration");
    
    Ok(())
}
