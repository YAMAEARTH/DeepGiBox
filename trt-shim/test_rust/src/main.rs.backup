use libloading::Library;
use std::path::Path;
use std::time::Instant;

fn main() {
    unsafe {
        let lib = Library::new("../build/libtrt_shim.so").expect("Failed to load library");
        
        let build_engine: libloading::Symbol<unsafe extern "C" fn(*const i8, *const i8)> = 
            lib.get(b"build_engine").expect("Failed to get build_engine function");

        let onnx = std::ffi::CString::new("assets/YOLOv5.onnx").unwrap();
        let engine = std::ffi::CString::new("assets/optimized_YOLOv5.engine").unwrap();

        if !Path::new("assets/optimized_YOLOv5.engine").exists() {
            println!("Building TensorRT engine...");
            build_engine(onnx.as_ptr(), engine.as_ptr());
        } else {
            println!("Using existing engine file");
        }
        
        if Path::new("assets/optimized_YOLOv5.engine").exists() {
            println!("✅ Engine file found");
            let metadata = std::fs::metadata("assets/optimized_YOLOv5.engine").unwrap();
            println!("   Size: {:.2} MB\n", metadata.len() as f64 / 1024.0 / 1024.0);
        } else {
            println!("❌ Engine file was not created!");
            return;
        }
        
        println!("=== Running Inference ===");
        
        // Fast session-based API
        type InferenceSession = *mut std::ffi::c_void;
        let create_session: libloading::Symbol<unsafe extern "C" fn(*const i8) -> InferenceSession> = 
            lib.get(b"create_session").expect("Failed to get create_session function");
        let run_inference: libloading::Symbol<unsafe extern "C" fn(InferenceSession, *const f32, *mut f32, i32, i32)> = 
            lib.get(b"run_inference").expect("Failed to get run_inference function");
        let destroy_session: libloading::Symbol<unsafe extern "C" fn(InferenceSession)> = 
            lib.get(b"destroy_session").expect("Failed to get destroy_session function");
            
        let input_size = 1 * 3 * 640 * 640;  // 640x640 input
        let output_size = 16128 * 7;  // 16128 detections, 2 classes (7 values each)
        
        println!("Input: {} floats ({} MB)", input_size, input_size * 4 / 1024 / 1024);
        println!("Output: {} floats ({} MB)", output_size, output_size * 4 / 1024 / 1024);
        
        // Create session (loads engine once)
        println!("\nCreating session...");
        let start_session = Instant::now();
        let session = create_session(engine.as_ptr());
        let session_time = start_session.elapsed();
        println!("⏱️  Session creation: {:.2} ms", session_time.as_secs_f64() * 1000.0);
        
        if session.is_null() {
            println!("❌ Failed to create session!");
            return;
        }
        
        let input_data: Vec<f32> = vec![0.5; input_size];
        let mut output_data: Vec<f32> = vec![0.0; output_size];
        
        // Warm-up run (first run allocates GPU buffers)
        println!("\nWarm-up run...");
        run_inference(session, input_data.as_ptr(), output_data.as_mut_ptr(), input_size as i32, output_size as i32);
        
        // Timed runs
        println!("\nTimed inference runs:");
        let num_runs = 5;
        let mut times = Vec::new();
        
        for i in 0..num_runs {
            let start = Instant::now();
            run_inference(session, input_data.as_ptr(), output_data.as_mut_ptr(), input_size as i32, output_size as i32);
            let duration = start.elapsed();
            let ms = duration.as_secs_f64() * 1000.0;
            times.push(ms);
            println!("  Run {}: {:.2} ms", i + 1, ms);
        }
        
        let avg_time = times.iter().sum::<f64>() / times.len() as f64;
        let min_time = times.iter().cloned().fold(f64::INFINITY, f64::min);
        let max_time = times.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
        
        println!("\n⏱️  Performance:");
        println!("  Average: {:.2} ms", avg_time);
        println!("  Min:     {:.2} ms", min_time);
        println!("  Max:     {:.2} ms", max_time);
        println!("  FPS:     {:.1}", 1000.0 / avg_time);
        
        println!("\n=== Results ===");
        println!("First 10 output values:");
        for (i, val) in output_data[..10].iter().enumerate() {
            println!("  [{}] = {:.6}", i, val);
        }
        
        let max_val = output_data.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
        let min_val = output_data.iter().cloned().fold(f32::INFINITY, f32::min);
        let avg_val = output_data.iter().sum::<f32>() / output_data.len() as f32;
        
        println!("\nStatistics:");
        println!("  Min:     {:.6}", min_val);
        println!("  Max:     {:.6}", max_val);
        println!("  Average: {:.6}", avg_val);
        println!("  Non-zero values: {}", output_data.iter().filter(|&&x| x != 0.0).count());
        
        // Cleanup session
        destroy_session(session);
        
        println!("\n✅ Complete!");
        
        std::mem::forget(lib);
    }
}
